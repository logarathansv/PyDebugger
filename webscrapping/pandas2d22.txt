Page: https://pandas.pydata.org/docs/whatsnew/v2.2.2.html
Whatâs new in 2.2.2 (April 10, 2024) # These are the changes in pandas 2.2.2. See Release notes for a full changelog
including other versions of pandas. Pandas 2.2.2 is now compatible with numpy 2.0 # Pandas 2.2.2 is the first version of pandas that is generally compatible with the upcoming
numpy 2.0 release, and wheels for pandas 2.2.2 will work with both numpy 1.x and 2.x. One major caveat is that arrays created with numpy 2.0âs new StringDtype will convert
to object dtyped arrays upon Series / DataFrame creation.
Full support for numpy 2.0âs StringDtype is expected to land in pandas 3.0. As usual please report any bugs discovered to our issue tracker Fixed regressions # DataFrame.__dataframe__() was producing incorrect data buffers when the a columnâs type was a pandas nullable on with missing values ( GH 56702 ) DataFrame.__dataframe__() was producing incorrect data buffers when the a columnâs type was a pyarrow nullable on with missing values ( GH 57664 ) Avoid issuing a spurious DeprecationWarning when a custom DataFrame or Series subclass method is called ( GH 57553 ) Fixed regression in precision of to_datetime() with string and unit input ( GH 57051 ) Bug fixes # DataFrame.__dataframe__() was producing incorrect data buffers when the columnâs type was nullable boolean ( GH 55332 ) DataFrame.__dataframe__() was showing bytemask instead of bitmask for 'string[pyarrow]' validity buffer ( GH 57762 ) DataFrame.__dataframe__() was showing non-null validity buffer (instead of None ) 'string[pyarrow]' without missing values ( GH 57761 ) DataFrame.to_sql() was failing to find the right table when using the schema argument ( GH 57539 ) Other # Contributors # A total of 20 people contributed patches to this release.  People with a
â+â by their names contributed a patch for the first time. ClÃ©ment Robert Elliott Sales de Andrade Lumberbot (aka Jack) Marc Garcia Marco Edward Gorelli Marco Gorelli Mateusz SokÃ³Å Matthew Roeschke Natalia Mokeeva Pandas Development Team Sebastian Berg Shabab Karim + Thomas Baumann Thomas Li Trinh Quoc Anh + William Ayd Yuki Kitayama + Zhengbo Wang dependabot[bot] jbrockmendel


Page: https://pandas.pydata.org/docs/whatsnew/index.html#release
Release notes # This is the list of changes to pandas between each release. For full details,
see the commit logs . For install and
upgrade instructions, see Installation . Version 2.2 # Whatâs new in 2.2.3 (September 20, 2024) Pandas 2.2.3 is now compatible with Python 3.13 Bug fixes Other Contributors Whatâs new in 2.2.2 (April 10, 2024) Pandas 2.2.2 is now compatible with numpy 2.0 Fixed regressions Bug fixes Other Contributors Whatâs new in 2.2.1 (February 22, 2024) Enhancements Fixed regressions Bug fixes Other Contributors Whatâs new in 2.2.0 (January 19, 2024) Upcoming changes in pandas 3.0 Enhancements Notable bug fixes Deprecations Performance improvements Bug fixes Contributors Version 2.1 # Whatâs new in 2.1.4 (December 8, 2023) Fixed regressions Bug fixes Contributors Whatâs new in 2.1.3 (November 10, 2023) Fixed regressions Bug fixes Contributors Whatâs new in 2.1.2 (October 26, 2023) Deprecations Fixed regressions Bug fixes Other Contributors Whatâs new in 2.1.1 (September 20, 2023) Fixed regressions Bug fixes Other Contributors Whatâs new in 2.1.0 (Aug 30, 2023) Enhancements Backwards incompatible API changes Deprecations Performance improvements Bug fixes Contributors Version 2.0 # Whatâs new in 2.0.3 (June 28, 2023) Fixed regressions Bug fixes Other Contributors Whatâs new in 2.0.2 (May 29, 2023) Fixed regressions Bug fixes Other Contributors Whatâs new in 2.0.1 (April 24, 2023) Fixed regressions Bug fixes Other Contributors Whatâs new in 2.0.0 (April 3, 2023) Enhancements Notable bug fixes Backwards incompatible API changes Deprecations Removal of prior version deprecations/changes Performance improvements Bug fixes Contributors Version 1.5 # Whatâs new in 1.5.3 (January 18, 2023) Fixed regressions Bug fixes Other Contributors Whatâs new in 1.5.2 (November 21, 2022) Fixed regressions Bug fixes Other Contributors Whatâs new in 1.5.1 (October 19, 2022) Behavior of groupby with categorical groupers (GH 48645) Fixed regressions Bug fixes Other Contributors Whatâs new in 1.5.0 (September 19, 2022) Enhancements Notable bug fixes Backwards incompatible API changes Deprecations Performance improvements Bug fixes Contributors Version 1.4 # Whatâs new in 1.4.4 (August 31, 2022) Fixed regressions Bug fixes Other Contributors Whatâs new in 1.4.3 (June 23, 2022) Behavior of concat with empty or all-NA DataFrame columns Fixed regressions Bug fixes Other Contributors Whatâs new in 1.4.2 (April 2, 2022) Fixed regressions Bug fixes Contributors Whatâs new in 1.4.1 (February 12, 2022) Fixed regressions Bug fixes Other Contributors Whatâs new in 1.4.0 (January 22, 2022) Enhancements Notable bug fixes Backwards incompatible API changes Deprecations Performance improvements Bug fixes Contributors Version 1.3 # Whatâs new in 1.3.5 (December 12, 2021) Fixed regressions Contributors Whatâs new in 1.3.4 (October 17, 2021) Fixed regressions Bug fixes Other Contributors Whatâs new in 1.3.3 (September 12, 2021) Fixed regressions Performance improvements Bug fixes Contributors Whatâs new in 1.3.2 (August 15, 2021) Fixed regressions Bug fixes Contributors Whatâs new in 1.3.1 (July 25, 2021) Fixed regressions Bug fixes Contributors Whatâs new in 1.3.0 (July 2, 2021) Enhancements Notable bug fixes Backwards incompatible API changes Deprecations Performance improvements Bug fixes Contributors Version 1.2 # Whatâs new in 1.2.5 (June 22, 2021) Fixed regressions Contributors Whatâs new in 1.2.4 (April 12, 2021) Fixed regressions Contributors Whatâs new in 1.2.3 (March 02, 2021) Fixed regressions Contributors Whatâs new in 1.2.2 (February 09, 2021) Fixed regressions Bug fixes Contributors Whatâs new in 1.2.1 (January 20, 2021) Fixed regressions Calling NumPy ufuncs on non-aligned DataFrames Bug fixes Other Contributors Whatâs new in 1.2.0 (December 26, 2020) Enhancements Notable bug fixes Deprecations Performance improvements Bug fixes Contributors Version 1.1 # Whatâs new in 1.1.5 (December 07, 2020) Fixed regressions Bug fixes Other Contributors Whatâs new in 1.1.4 (October 30, 2020) Fixed regressions Bug fixes Contributors Whatâs new in 1.1.3 (October 5, 2020) Enhancements Fixed regressions Bug fixes Other Contributors Whatâs new in 1.1.2 (September 8, 2020) Fixed regressions Bug fixes Other Contributors Whatâs new in 1.1.1 (August 20, 2020) Fixed regressions Bug fixes Contributors Whatâs new in 1.1.0 (July 28, 2020) Enhancements Notable bug fixes Backwards incompatible API changes Deprecations Performance improvements Bug fixes Contributors Version 1.0 # Whatâs new in 1.0.5 (June 17, 2020) Fixed regressions Bug fixes Contributors Whatâs new in 1.0.4 (May 28, 2020) Fixed regressions Bug fixes Contributors Whatâs new in 1.0.3 (March 17, 2020) Fixed regressions Bug fixes Contributors Whatâs new in 1.0.2 (March 12, 2020) Fixed regressions Indexing with nullable boolean arrays Bug fixes Contributors Whatâs new in 1.0.1 (February 5, 2020) Fixed regressions Deprecations Bug fixes Contributors Whatâs new in 1.0.0 (January 29, 2020) New deprecation policy Enhancements Experimental new features Other enhancements Backwards incompatible API changes Deprecations Removal of prior version deprecations/changes Performance improvements Bug fixes Contributors Version 0.25 # Whatâs new in 0.25.3 (October 31, 2019) Bug fixes Contributors Whatâs new in 0.25.2 (October 15, 2019) Bug fixes Contributors Whatâs new in 0.25.1 (August 21, 2019) IO and LZMA Bug fixes Contributors Whatâs new in 0.25.0 (July 18, 2019) Enhancements Backwards incompatible API changes Deprecations Removal of prior version deprecations/changes Performance improvements Bug fixes Contributors Version 0.24 # Whatâs new in 0.24.2 (March 12, 2019) Fixed regressions Bug fixes Contributors Whatâs new in 0.24.1 (February 3, 2019) API changes Fixed regressions Bug fixes Contributors Whatâs new in 0.24.0 (January 25, 2019) Enhancements Backwards incompatible API changes Extension type changes Deprecations Removal of prior version deprecations/changes Performance improvements Bug fixes Contributors Version 0.23 # Whatâs new in 0.23.4 (August 3, 2018) Fixed regressions Bug fixes Contributors Whatâs new in 0.23.3 (July 7, 2018) Contributors Whatâs new in 0.23.2 (July 5, 2018) Logical reductions over entire DataFrame Fixed regressions Build changes Bug fixes Contributors Whatâs new in 0.23.1 (June 12, 2018) Fixed regressions Performance improvements Bug fixes Contributors Whatâs new in 0.23.0 (May 15, 2018) New features Backwards incompatible API changes Deprecations Removal of prior version deprecations/changes Performance improvements Documentation changes Bug fixes Contributors Version 0.22 # Version 0.22.0 (December 29, 2017) Backwards incompatible API changes Compatibility Contributors Version 0.21 # Version 0.21.1 (December 12, 2017) Restore Matplotlib datetime converter registration New features Deprecations Performance improvements Bug fixes Contributors Version 0.21.0 (October 27, 2017) New features Backwards incompatible API changes Deprecations Removal of prior version deprecations/changes Performance improvements Documentation changes Bug fixes Contributors Version 0.20 # Version 0.20.3 (July 7, 2017) Bug fixes Contributors Version 0.20.2 (June 4, 2017) Enhancements Performance improvements Bug fixes Contributors Version 0.20.1 (May 5, 2017) New features Backwards incompatible API changes Reorganization of the library: privacy changes Deprecations Removal of prior version deprecations/changes Performance improvements Bug fixes Contributors Version 0.19 # Version 0.19.2 (December 24, 2016) Enhancements Performance improvements Bug fixes Contributors Version 0.19.1 (November 3, 2016) Performance improvements Bug fixes Contributors Version 0.19.0 (October 2, 2016) New features API changes Deprecations Removal of prior version deprecations/changes Performance improvements Bug fixes Contributors Version 0.18 # Version 0.18.1 (May 3, 2016) New features Sparse changes API changes Performance improvements Bug fixes Contributors Version 0.18.0 (March 13, 2016) New features Backwards incompatible API changes Performance improvements Bug fixes Contributors Version 0.17 # Version 0.17.1 (November 21, 2015) New features Enhancements API changes Performance improvements Bug fixes Contributors Version 0.17.0 (October 9, 2015) New features Backwards incompatible API changes Performance improvements Bug fixes Contributors Version 0.16 # Version 0.16.2 (June 12, 2015) New features API changes Performance improvements Bug fixes Contributors Version 0.16.1 (May 11, 2015) Enhancements API changes Index representation Performance improvements Bug fixes Contributors Version 0.16.0 (March 22, 2015) New features Backwards incompatible API changes Performance improvements Bug fixes Contributors Version 0.15 # Version 0.15.2 (December 12, 2014) API changes Enhancements Performance Bug fixes Contributors Version 0.15.1 (November 9, 2014) API changes Enhancements Bug fixes Contributors Version 0.15.0 (October 18, 2014) New features Backwards incompatible API changes Enhancements Performance Bug fixes Contributors Version 0.14 # Version 0.14.1 (July 11, 2014) API changes Enhancements Performance Experimental Bug fixes Contributors Version 0.14.0 (May 31 , 2014) API changes Display changes Text parsing API changes GroupBy API changes SQL Multi-indexing using slicers Plotting Prior version deprecations/changes Deprecations Known issues Enhancements Performance Experimental Bug fixes Contributors Version 0.13 # Version 0.13.1 (February 3, 2014) Output formatting enhancements API changes Prior version deprecations/changes Deprecations Enhancements Performance Experimental Bug fixes Contributors Version 0.13.0 (January 3, 2014) API changes Prior version deprecations/changes Deprecations Indexing API changes Float64Index API change HDFStore API changes DataFrame repr changes Enhancements Experimental Internal refactoring Bug fixes Contributors Version 0.12 # Version 0.12.0 (July 24, 2013) API changes IO enhancements Other enhancements Experimental features Bug fixes Contributors Version 0.11 # Version 0.11.0 (April 22, 2013) Selection choices Selection deprecations Dtypes Dtype conversion Dtype gotchas Datetimes conversion API changes Enhancements Contributors Version 0.10 # Version 0.10.1 (January 22, 2013) API changes New features HDFStore Contributors Version 0.10.0 (December 17, 2012) File parsing new features API changes New features Wide DataFrame printing Updated PyTables support N dimensional panels (experimental) Contributors Version 0.9 # Version 0.9.1 (November 14, 2012) New features API changes Contributors Version 0.9.0 (October 7, 2012) New features API changes Contributors Version 0.8 # Version 0.8.1 (July 22, 2012) New features Performance improvements Contributors Version 0.8.0 (June 29, 2012) Support for non-unique indexes NumPy datetime64 dtype and 1.6 dependency Time Series changes and improvements Other new features New plotting methods Other API changes Potential porting issues for pandas <= 0.7.3 users Contributors Version 0.7 # Version 0.7.3 (April 12, 2012) New features NA boolean comparison API change Other API changes Contributors Version 0.7.2 (March 16, 2012) New features Performance improvements Contributors Version 0.7.1 (February 29, 2012) New features Performance improvements Contributors Version 0.7.0 (February 9, 2012) New features API changes to integer indexing API tweaks regarding label-based slicing Changes to Series [] operator Other API changes Performance improvements Contributors Version 0.6 # Version 0.6.1 (December 13, 2011) New features Performance improvements Contributors Version 0.6.0 (November 25, 2011) New features Performance enhancements Contributors Version 0.5 # Version 0.5.0 (October 24, 2011) New features Performance enhancements Contributors Version 0.4 # Versions 0.4.1 through 0.4.3 (September 25 - October 9, 2011) New features Performance enhancements Contributors


Page: https://pandas.pydata.org/docs/reference/api/pandas.Series.html#pandas.Series
pandas.Series # class pandas. Series ( data=None , index=None , dtype=None , name=None , copy=None , fastpath=<no_default> ) [source] # One-dimensional ndarray with axis labels (including time series). Labels need not be unique but must be a hashable type. The object
supports both integer- and label-based indexing and provides a host of
methods for performing operations involving the index. Statistical
methods from ndarray have been overridden to automatically exclude
missing data (currently represented as NaN). Operations between Series (+, -, /, *, **) align values based on their
associated index valuesâ they need not be the same length. The result
index will be the sorted union of the two indexes. Parameters : data array-like, Iterable, dict, or scalar value Contains data stored in Series. If data is a dict, argument order is
maintained. index array-like or Index (1d) Values must be hashable and have the same length as data .
Non-unique index values are allowed. Will default to
RangeIndex (0, 1, 2, â¦, n) if not provided. If data is dict-like
and index is None, then the keys in the data are used as the index. If the
index is not None, the resulting Series is reindexed with the index values. dtype str, numpy.dtype, or ExtensionDtype, optional Data type for the output Series. If not specified, this will be
inferred from data .
See the user guide for more usages. name Hashable, default None The name to give to the Series. copy bool, default False Copy input data. Only affects Series or 1d ndarray input. See examples. Notes Please reference the User Guide for more information. Examples Constructing Series from a dictionary with an Index specified >>> d = { 'a' : 1 , 'b' : 2 , 'c' : 3 } >>> ser = pd . Series ( data = d , index = [ 'a' , 'b' , 'c' ]) >>> ser a   1 b   2 c   3 dtype: int64 The keys of the dictionary match with the Index values, hence the Index
values have no effect. >>> d = { 'a' : 1 , 'b' : 2 , 'c' : 3 } >>> ser = pd . Series ( data = d , index = [ 'x' , 'y' , 'z' ]) >>> ser x   NaN y   NaN z   NaN dtype: float64 Note that the Index is first build with the keys from the dictionary.
After this the Series is reindexed with the given Index values, hence we
get all NaN as a result. Constructing Series from a list with copy=False . >>> r = [ 1 , 2 ] >>> ser = pd . Series ( r , copy = False ) >>> ser . iloc [ 0 ] = 999 >>> r [1, 2] >>> ser 0    999 1      2 dtype: int64 Due to input data type the Series has a copy of
the original data even though copy=False , so
the data is unchanged. Constructing Series from a 1d ndarray with copy=False . >>> r = np . array ([ 1 , 2 ]) >>> ser = pd . Series ( r , copy = False ) >>> ser . iloc [ 0 ] = 999 >>> r array([999,   2]) >>> ser 0    999 1      2 dtype: int64 Due to input data type the Series has a view on
the original data, so
the data is changed as well. Attributes T Return the transpose, which is by definition self. array The ExtensionArray of the data backing this Series or Index. at Access a single value for a row/column label pair. attrs Dictionary of global attributes of this dataset. axes Return a list of the row axis labels. dtype Return the dtype object of the underlying data. dtypes Return the dtype object of the underlying data. empty Indicator whether Series/DataFrame is empty. flags Get the properties associated with this pandas object. hasnans Return True if there are any NaNs. iat Access a single value for a row/column pair by integer position. iloc (DEPRECATED) Purely integer-location based indexing for selection by position. index The index (axis labels) of the Series. is_monotonic_decreasing Return boolean if values in the object are monotonically decreasing. is_monotonic_increasing Return boolean if values in the object are monotonically increasing. is_unique Return boolean if values in the object are unique. loc Access a group of rows and columns by label(s) or a boolean array. name Return the name of the Series. nbytes Return the number of bytes in the underlying data. ndim Number of dimensions of the underlying data, by definition 1. shape Return a tuple of the shape of the underlying data. size Return the number of elements in the underlying data. values Return Series as ndarray or ndarray-like depending on the dtype. Methods abs () Return a Series/DataFrame with absolute numeric value of each element. add (other[,Â level,Â fill_value,Â axis]) Return Addition of series and other, element-wise (binary operator add ). add_prefix (prefix[,Â axis]) Prefix labels with string prefix . add_suffix (suffix[,Â axis]) Suffix labels with string suffix . agg ([func,Â axis]) Aggregate using one or more operations over the specified axis. aggregate ([func,Â axis]) Aggregate using one or more operations over the specified axis. align (other[,Â join,Â axis,Â level,Â copy,Â ...]) Align two objects on their axes with the specified join method. all ([axis,Â bool_only,Â skipna]) Return whether all elements are True, potentially over an axis. any (*[,Â axis,Â bool_only,Â skipna]) Return whether any element is True, potentially over an axis. apply (func[,Â convert_dtype,Â args,Â by_row]) Invoke function on values of Series. argmax ([axis,Â skipna]) Return int position of the largest value in the Series. argmin ([axis,Â skipna]) Return int position of the smallest value in the Series. argsort ([axis,Â kind,Â order,Â stable]) Return the integer indices that would sort the Series values. asfreq (freq[,Â method,Â how,Â normalize,Â ...]) Convert time series to specified frequency. asof (where[,Â subset]) Return the last row(s) without any NaNs before where . astype (dtype[,Â copy,Â errors]) Cast a pandas object to a specified dtype dtype . at_time (time[,Â asof,Â axis]) Select values at particular time of day (e.g., 9:30AM). autocorr ([lag]) Compute the lag-N autocorrelation. backfill (*[,Â axis,Â inplace,Â limit,Â downcast]) (DEPRECATED) Fill NA/NaN values by using the next valid observation to fill the gap. between (left,Â right[,Â inclusive]) Return boolean Series equivalent to left <= series <= right. between_time (start_time,Â end_time[,Â ...]) Select values between particular times of the day (e.g., 9:00-9:30 AM). bfill (*[,Â axis,Â inplace,Â limit,Â limit_area,Â ...]) Fill NA/NaN values by using the next valid observation to fill the gap. bool () (DEPRECATED) Return the bool of a single element Series or DataFrame. case_when (caselist) Replace values where the conditions are True. clip ([lower,Â upper,Â axis,Â inplace]) Trim values at input threshold(s). combine (other,Â func[,Â fill_value]) Combine the Series with a Series or scalar according to func . combine_first (other) Update null elements with value in the same location in 'other'. compare (other[,Â align_axis,Â keep_shape,Â ...]) Compare to another Series and show the differences. convert_dtypes ([infer_objects,Â ...]) Convert columns to the best possible dtypes using dtypes supporting pd.NA . copy ([deep]) Make a copy of this object's indices and data. corr (other[,Â method,Â min_periods]) Compute correlation with other Series, excluding missing values. count () Return number of non-NA/null observations in the Series. cov (other[,Â min_periods,Â ddof]) Compute covariance with Series, excluding missing values. cummax ([axis,Â skipna]) Return cumulative maximum over a DataFrame or Series axis. cummin ([axis,Â skipna]) Return cumulative minimum over a DataFrame or Series axis. cumprod ([axis,Â skipna]) Return cumulative product over a DataFrame or Series axis. cumsum ([axis,Â skipna]) Return cumulative sum over a DataFrame or Series axis. describe ([percentiles,Â include,Â exclude]) Generate descriptive statistics. diff ([periods]) First discrete difference of element. div (other[,Â level,Â fill_value,Â axis]) Return Floating division of series and other, element-wise (binary operator truediv ). divide (other[,Â level,Â fill_value,Â axis]) Return Floating division of series and other, element-wise (binary operator truediv ). divmod (other[,Â level,Â fill_value,Â axis]) Return Integer division and modulo of series and other, element-wise (binary operator divmod ). dot (other) Compute the dot product between the Series and the columns of other. drop ([labels,Â axis,Â index,Â columns,Â level,Â ...]) Return Series with specified index labels removed. drop_duplicates (*[,Â keep,Â inplace,Â ignore_index]) Return Series with duplicate values removed. droplevel (level[,Â axis]) Return Series/DataFrame with requested index / column level(s) removed. dropna (*[,Â axis,Â inplace,Â how,Â ignore_index]) Return a new Series with missing values removed. duplicated ([keep]) Indicate duplicate Series values. eq (other[,Â level,Â fill_value,Â axis]) Return Equal to of series and other, element-wise (binary operator eq ). equals (other) Test whether two objects contain the same elements. ewm ([com,Â span,Â halflife,Â alpha,Â ...]) Provide exponentially weighted (EW) calculations. expanding ([min_periods,Â axis,Â method]) Provide expanding window calculations. explode ([ignore_index]) Transform each element of a list-like to a row. factorize ([sort,Â use_na_sentinel]) Encode the object as an enumerated type or categorical variable. ffill (*[,Â axis,Â inplace,Â limit,Â limit_area,Â ...]) Fill NA/NaN values by propagating the last valid observation to next valid. fillna ([value,Â method,Â axis,Â inplace,Â ...]) Fill NA/NaN values using the specified method. filter ([items,Â like,Â regex,Â axis]) Subset the dataframe rows or columns according to the specified index labels. first (offset) (DEPRECATED) Select initial periods of time series data based on a date offset. first_valid_index () Return index for first non-NA value or None, if no non-NA value is found. floordiv (other[,Â level,Â fill_value,Â axis]) Return Integer division of series and other, element-wise (binary operator floordiv ). ge (other[,Â level,Â fill_value,Â axis]) Return Greater than or equal to of series and other, element-wise (binary operator ge ). get (key[,Â default]) Get item from object for given key (ex: DataFrame column). groupby ([by,Â axis,Â level,Â as_index,Â sort,Â ...]) Group Series using a mapper or by a Series of columns. gt (other[,Â level,Â fill_value,Â axis]) Return Greater than of series and other, element-wise (binary operator gt ). head ([n]) Return the first n rows. hist ([by,Â ax,Â grid,Â xlabelsize,Â xrot,Â ...]) Draw histogram of the input series using matplotlib. idxmax ([axis,Â skipna]) Return the row label of the maximum value. idxmin ([axis,Â skipna]) Return the row label of the minimum value. infer_objects ([copy]) Attempt to infer better dtypes for object columns. info ([verbose,Â buf,Â max_cols,Â memory_usage,Â ...]) Print a concise summary of a Series. interpolate ([method,Â axis,Â limit,Â inplace,Â ...]) Fill NaN values using an interpolation method. isin (values) Whether elements in Series are contained in values . isna () Detect missing values. isnull () Series.isnull is an alias for Series.isna. item () Return the first element of the underlying data as a Python scalar. items () Lazily iterate over (index, value) tuples. keys () Return alias for index. kurt ([axis,Â skipna,Â numeric_only]) Return unbiased kurtosis over requested axis. kurtosis ([axis,Â skipna,Â numeric_only]) Return unbiased kurtosis over requested axis. last (offset) (DEPRECATED) Select final periods of time series data based on a date offset. last_valid_index () Return index for last non-NA value or None, if no non-NA value is found. le (other[,Â level,Â fill_value,Â axis]) Return Less than or equal to of series and other, element-wise (binary operator le ). lt (other[,Â level,Â fill_value,Â axis]) Return Less than of series and other, element-wise (binary operator lt ). map (arg[,Â na_action]) Map values of Series according to an input mapping or function. mask (cond[,Â other,Â inplace,Â axis,Â level]) Replace values where the condition is True. max ([axis,Â skipna,Â numeric_only]) Return the maximum of the values over the requested axis. mean ([axis,Â skipna,Â numeric_only]) Return the mean of the values over the requested axis. median ([axis,Â skipna,Â numeric_only]) Return the median of the values over the requested axis. memory_usage ([index,Â deep]) Return the memory usage of the Series. min ([axis,Â skipna,Â numeric_only]) Return the minimum of the values over the requested axis. mod (other[,Â level,Â fill_value,Â axis]) Return Modulo of series and other, element-wise (binary operator mod ). mode ([dropna]) Return the mode(s) of the Series. mul (other[,Â level,Â fill_value,Â axis]) Return Multiplication of series and other, element-wise (binary operator mul ). multiply (other[,Â level,Â fill_value,Â axis]) Return Multiplication of series and other, element-wise (binary operator mul ). ne (other[,Â level,Â fill_value,Â axis]) Return Not equal to of series and other, element-wise (binary operator ne ). nlargest ([n,Â keep]) Return the largest n elements. notna () Detect existing (non-missing) values. notnull () Series.notnull is an alias for Series.notna. nsmallest ([n,Â keep]) Return the smallest n elements. nunique ([dropna]) Return number of unique elements in the object. pad (*[,Â axis,Â inplace,Â limit,Â downcast]) (DEPRECATED) Fill NA/NaN values by propagating the last valid observation to next valid. pct_change ([periods,Â fill_method,Â limit,Â freq]) Fractional change between the current and a prior element. pipe (func,Â *args,Â **kwargs) Apply chainable functions that expect Series or DataFrames. pop (item) Return item and drops from series. pow (other[,Â level,Â fill_value,Â axis]) Return Exponential power of series and other, element-wise (binary operator pow ). prod ([axis,Â skipna,Â numeric_only,Â min_count]) Return the product of the values over the requested axis. product ([axis,Â skipna,Â numeric_only,Â min_count]) Return the product of the values over the requested axis. quantile ([q,Â interpolation]) Return value at the given quantile. radd (other[,Â level,Â fill_value,Â axis]) Return Addition of series and other, element-wise (binary operator radd ). rank ([axis,Â method,Â numeric_only,Â ...]) Compute numerical data ranks (1 through n) along axis. ravel ([order]) (DEPRECATED) Return the flattened underlying data as an ndarray or ExtensionArray. rdiv (other[,Â level,Â fill_value,Â axis]) Return Floating division of series and other, element-wise (binary operator rtruediv ). rdivmod (other[,Â level,Â fill_value,Â axis]) Return Integer division and modulo of series and other, element-wise (binary operator rdivmod ). reindex ([index,Â axis,Â method,Â copy,Â level,Â ...]) Conform Series to new index with optional filling logic. reindex_like (other[,Â method,Â copy,Â limit,Â ...]) Return an object with matching indices as other object. rename ([index,Â axis,Â copy,Â inplace,Â level,Â ...]) Alter Series index labels or name. rename_axis ([mapper,Â index,Â axis,Â copy,Â inplace]) Set the name of the axis for the index or columns. reorder_levels (order) Rearrange index levels using input order. repeat (repeats[,Â axis]) Repeat elements of a Series. replace ([to_replace,Â value,Â inplace,Â limit,Â ...]) Replace values given in to_replace with value . resample (rule[,Â axis,Â closed,Â label,Â ...]) Resample time-series data. reset_index ([level,Â drop,Â name,Â inplace,Â ...]) Generate a new DataFrame or Series with the index reset. rfloordiv (other[,Â level,Â fill_value,Â axis]) Return Integer division of series and other, element-wise (binary operator rfloordiv ). rmod (other[,Â level,Â fill_value,Â axis]) Return Modulo of series and other, element-wise (binary operator rmod ). rmul (other[,Â level,Â fill_value,Â axis]) Return Multiplication of series and other, element-wise (binary operator rmul ). rolling (window[,Â min_periods,Â center,Â ...]) Provide rolling window calculations. round ([decimals]) Round each value in a Series to the given number of decimals. rpow (other[,Â level,Â fill_value,Â axis]) Return Exponential power of series and other, element-wise (binary operator rpow ). rsub (other[,Â level,Â fill_value,Â axis]) Return Subtraction of series and other, element-wise (binary operator rsub ). rtruediv (other[,Â level,Â fill_value,Â axis]) Return Floating division of series and other, element-wise (binary operator rtruediv ). sample ([n,Â frac,Â replace,Â weights,Â ...]) Return a random sample of items from an axis of object. searchsorted (value[,Â side,Â sorter]) Find indices where elements should be inserted to maintain order. sem ([axis,Â skipna,Â ddof,Â numeric_only]) Return unbiased standard error of the mean over requested axis. set_axis (labels,Â *[,Â axis,Â copy]) Assign desired index to given axis. set_flags (*[,Â copy,Â allows_duplicate_labels]) Return a new object with updated flags. shift ([periods,Â freq,Â axis,Â fill_value,Â suffix]) Shift index by desired number of periods with an optional time freq . skew ([axis,Â skipna,Â numeric_only]) Return unbiased skew over requested axis. sort_index (*[,Â axis,Â level,Â ascending,Â ...]) Sort Series by index labels. sort_values (*[,Â axis,Â ascending,Â inplace,Â ...]) Sort by the values. squeeze ([axis]) Squeeze 1 dimensional axis objects into scalars. std ([axis,Â skipna,Â ddof,Â numeric_only]) Return sample standard deviation over requested axis. sub (other[,Â level,Â fill_value,Â axis]) Return Subtraction of series and other, element-wise (binary operator sub ). subtract (other[,Â level,Â fill_value,Â axis]) Return Subtraction of series and other, element-wise (binary operator sub ). sum ([axis,Â skipna,Â numeric_only,Â min_count]) Return the sum of the values over the requested axis. swapaxes (axis1,Â axis2[,Â copy]) (DEPRECATED) Interchange axes and swap values axes appropriately. swaplevel ([i,Â j,Â copy]) Swap levels i and j in a MultiIndex . tail ([n]) Return the last n rows. take (indices[,Â axis]) Return the elements in the given positional indices along an axis. to_clipboard (*[,Â excel,Â sep]) Copy object to the system clipboard. to_csv ([path_or_buf,Â sep,Â na_rep,Â ...]) Write object to a comma-separated values (csv) file. to_dict (*[,Â into]) Convert Series to {label -> value} dict or dict-like object. to_excel (excel_writer,Â *[,Â sheet_name,Â ...]) Write object to an Excel sheet. to_frame ([name]) Convert Series to DataFrame. to_hdf (path_or_buf,Â *,Â key[,Â mode,Â ...]) Write the contained data to an HDF5 file using HDFStore. to_json ([path_or_buf,Â orient,Â date_format,Â ...]) Convert the object to a JSON string. to_latex ([buf,Â columns,Â header,Â index,Â ...]) Render object to a LaTeX tabular, longtable, or nested table. to_list () Return a list of the values. to_markdown ([buf,Â mode,Â index,Â storage_options]) Print Series in Markdown-friendly format. to_numpy ([dtype,Â copy,Â na_value]) A NumPy ndarray representing the values in this Series or Index. to_period ([freq,Â copy]) Convert Series from DatetimeIndex to PeriodIndex. to_pickle (path,Â *[,Â compression,Â protocol,Â ...]) Pickle (serialize) object to file. to_sql (name,Â con,Â *[,Â schema,Â if_exists,Â ...]) Write records stored in a DataFrame to a SQL database. to_string ([buf,Â na_rep,Â float_format,Â ...]) Render a string representation of the Series. to_timestamp ([freq,Â how,Â copy]) Cast to DatetimeIndex of Timestamps, at beginning of period. to_xarray () Return an xarray object from the pandas object. tolist () Return a list of the values. transform (func[,Â axis]) Call func on self producing a Series with the same axis shape as self. transpose (*args,Â **kwargs) Return the transpose, which is by definition self. truediv (other[,Â level,Â fill_value,Â axis]) Return Floating division of series and other, element-wise (binary operator truediv ). truncate ([before,Â after,Â axis,Â copy]) Truncate a Series or DataFrame before and after some index value. tz_convert (tz[,Â axis,Â level,Â copy]) Convert tz-aware axis to target time zone. tz_localize (tz[,Â axis,Â level,Â copy,Â ...]) Localize tz-naive index of a Series or DataFrame to target time zone. unique () Return unique values of Series object. unstack ([level,Â fill_value,Â sort]) Unstack, also known as pivot, Series with MultiIndex to produce DataFrame. update (other) Modify Series in place using values from passed Series. value_counts ([normalize,Â sort,Â ascending,Â ...]) Return a Series containing counts of unique values. var ([axis,Â skipna,Â ddof,Â numeric_only]) Return unbiased variance over requested axis. view ([dtype]) (DEPRECATED) Create a new view of the Series. where (cond[,Â other,Â inplace,Â axis,Â level]) Replace values where the condition is False. xs (key[,Â axis,Â level,Â drop_level]) Return cross-section from the Series/DataFrame.


Page: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame
pandas.DataFrame # class pandas. DataFrame ( data = None , index = None , columns = None , dtype = None , copy = None ) [source] # Two-dimensional, size-mutable, potentially heterogeneous tabular data. Data structure also contains labeled axes (rows and columns).
Arithmetic operations align on both row and column labels. Can be
thought of as a dict-like container for Series objects. The primary
pandas data structure. Parameters : data ndarray (structured or homogeneous), Iterable, dict, or DataFrame Dict can contain Series, arrays, constants, dataclass or list-like objects. If
data is a dict, column order follows insertion-order. If a dict contains Series
which have an index defined, it is aligned by its index. This alignment also
occurs if data is a Series or a DataFrame itself. Alignment is done on
Series/DataFrame inputs. If data is a list of dicts, column order follows insertion-order. index Index or array-like Index to use for resulting frame. Will default to RangeIndex if
no indexing information part of input data and no index provided. columns Index or array-like Column labels to use for resulting frame when data does not have them,
defaulting to RangeIndex(0, 1, 2, â¦, n). If data contains column labels,
will perform column selection instead. dtype dtype, default None Data type to force. Only a single dtype is allowed. If None, infer. copy bool or None, default None Copy data from inputs.
For dict data, the default of None behaves like copy=True .  For DataFrame
or 2d ndarray input, the default of None behaves like copy=False .
If data is a dict containing one or more Series (possibly of different dtypes), copy=False will ensure that these inputs are not copied. Changed in version 1.3.0. See also DataFrame.from_records Constructor from tuples, also record arrays. DataFrame.from_dict From dicts of Series, arrays, or dicts. read_csv Read a comma-separated values (csv) file into DataFrame. read_table Read general delimited file into DataFrame. read_clipboard Read text from clipboard into DataFrame. Notes Please reference the User Guide for more information. Examples Constructing DataFrame from a dictionary. >>> d = { 'col1' : [ 1 , 2 ], 'col2' : [ 3 , 4 ]} >>> df = pd . DataFrame ( data = d ) >>> df col1  col2 0     1     3 1     2     4 Notice that the inferred dtype is int64. >>> df . dtypes col1    int64 col2    int64 dtype: object To enforce a single dtype: >>> df = pd . DataFrame ( data = d , dtype = np . int8 ) >>> df . dtypes col1    int8 col2    int8 dtype: object Constructing DataFrame from a dictionary including Series: >>> d = { 'col1' : [ 0 , 1 , 2 , 3 ], 'col2' : pd . Series ([ 2 , 3 ], index = [ 2 , 3 ])} >>> pd . DataFrame ( data = d , index = [ 0 , 1 , 2 , 3 ]) col1  col2 0     0   NaN 1     1   NaN 2     2   2.0 3     3   3.0 Constructing DataFrame from numpy ndarray: >>> df2 = pd . DataFrame ( np . array ([[ 1 , 2 , 3 ], [ 4 , 5 , 6 ], [ 7 , 8 , 9 ]]), ... columns = [ 'a' , 'b' , 'c' ]) >>> df2 a  b  c 0  1  2  3 1  4  5  6 2  7  8  9 Constructing DataFrame from a numpy ndarray that has labeled columns: >>> data = np . array ([( 1 , 2 , 3 ), ( 4 , 5 , 6 ), ( 7 , 8 , 9 )], ... dtype = [( "a" , "i4" ), ( "b" , "i4" ), ( "c" , "i4" )]) >>> df3 = pd . DataFrame ( data , columns = [ 'c' , 'a' ]) ... >>> df3 c  a 0  3  1 1  6  4 2  9  7 Constructing DataFrame from dataclass: >>> from dataclasses import make_dataclass >>> Point = make_dataclass ( "Point" , [( "x" , int ), ( "y" , int )]) >>> pd . DataFrame ([ Point ( 0 , 0 ), Point ( 0 , 3 ), Point ( 2 , 3 )]) x  y 0  0  0 1  0  3 2  2  3 Constructing DataFrame from Series/DataFrame: >>> ser = pd . Series ([ 1 , 2 , 3 ], index = [ "a" , "b" , "c" ]) >>> df = pd . DataFrame ( data = ser , index = [ "a" , "c" ]) >>> df 0 a  1 c  3 >>> df1 = pd . DataFrame ([ 1 , 2 , 3 ], index = [ "a" , "b" , "c" ], columns = [ "x" ]) >>> df2 = pd . DataFrame ( data = df1 , index = [ "a" , "c" ]) >>> df2 x a  1 c  3 Attributes T The transpose of the DataFrame. at Access a single value for a row/column label pair. attrs Dictionary of global attributes of this dataset. axes Return a list representing the axes of the DataFrame. columns The column labels of the DataFrame. dtypes Return the dtypes in the DataFrame. empty Indicator whether Series/DataFrame is empty. flags Get the properties associated with this pandas object. iat Access a single value for a row/column pair by integer position. iloc (DEPRECATED) Purely integer-location based indexing for selection by position. index The index (row labels) of the DataFrame. loc Access a group of rows and columns by label(s) or a boolean array. ndim Return an int representing the number of axes / array dimensions. shape Return a tuple representing the dimensionality of the DataFrame. size Return an int representing the number of elements in this object. style Returns a Styler object. values Return a Numpy representation of the DataFrame. Methods abs () Return a Series/DataFrame with absolute numeric value of each element. add (other[,Â axis,Â level,Â fill_value]) Get Addition of dataframe and other, element-wise (binary operator add ). add_prefix (prefix[,Â axis]) Prefix labels with string prefix . add_suffix (suffix[,Â axis]) Suffix labels with string suffix . agg ([func,Â axis]) Aggregate using one or more operations over the specified axis. aggregate ([func,Â axis]) Aggregate using one or more operations over the specified axis. align (other[,Â join,Â axis,Â level,Â copy,Â ...]) Align two objects on their axes with the specified join method. all ([axis,Â bool_only,Â skipna]) Return whether all elements are True, potentially over an axis. any (*[,Â axis,Â bool_only,Â skipna]) Return whether any element is True, potentially over an axis. apply (func[,Â axis,Â raw,Â result_type,Â args,Â ...]) Apply a function along an axis of the DataFrame. applymap (func[,Â na_action]) (DEPRECATED) Apply a function to a Dataframe elementwise. asfreq (freq[,Â method,Â how,Â normalize,Â ...]) Convert time series to specified frequency. asof (where[,Â subset]) Return the last row(s) without any NaNs before where . assign (**kwargs) Assign new columns to a DataFrame. astype (dtype[,Â copy,Â errors]) Cast a pandas object to a specified dtype dtype . at_time (time[,Â asof,Â axis]) Select values at particular time of day (e.g., 9:30AM). backfill (*[,Â axis,Â inplace,Â limit,Â downcast]) (DEPRECATED) Fill NA/NaN values by using the next valid observation to fill the gap. between_time (start_time,Â end_time[,Â ...]) Select values between particular times of the day (e.g., 9:00-9:30 AM). bfill (*[,Â axis,Â inplace,Â limit,Â limit_area,Â ...]) Fill NA/NaN values by using the next valid observation to fill the gap. bool () (DEPRECATED) Return the bool of a single element Series or DataFrame. boxplot ([column,Â by,Â ax,Â fontsize,Â rot,Â ...]) Make a box plot from DataFrame columns. clip ([lower,Â upper,Â axis,Â inplace]) Trim values at input threshold(s). combine (other,Â func[,Â fill_value,Â overwrite]) Perform column-wise combine with another DataFrame. combine_first (other) Update null elements with value in the same location in other . compare (other[,Â align_axis,Â keep_shape,Â ...]) Compare to another DataFrame and show the differences. convert_dtypes ([infer_objects,Â ...]) Convert columns to the best possible dtypes using dtypes supporting pd.NA . copy ([deep]) Make a copy of this object's indices and data. corr ([method,Â min_periods,Â numeric_only]) Compute pairwise correlation of columns, excluding NA/null values. corrwith (other[,Â axis,Â drop,Â method,Â ...]) Compute pairwise correlation. count ([axis,Â numeric_only]) Count non-NA cells for each column or row. cov ([min_periods,Â ddof,Â numeric_only]) Compute pairwise covariance of columns, excluding NA/null values. cummax ([axis,Â skipna]) Return cumulative maximum over a DataFrame or Series axis. cummin ([axis,Â skipna]) Return cumulative minimum over a DataFrame or Series axis. cumprod ([axis,Â skipna]) Return cumulative product over a DataFrame or Series axis. cumsum ([axis,Â skipna]) Return cumulative sum over a DataFrame or Series axis. describe ([percentiles,Â include,Â exclude]) Generate descriptive statistics. diff ([periods,Â axis]) First discrete difference of element. div (other[,Â axis,Â level,Â fill_value]) Get Floating division of dataframe and other, element-wise (binary operator truediv ). divide (other[,Â axis,Â level,Â fill_value]) Get Floating division of dataframe and other, element-wise (binary operator truediv ). dot (other) Compute the matrix multiplication between the DataFrame and other. drop ([labels,Â axis,Â index,Â columns,Â level,Â ...]) Drop specified labels from rows or columns. drop_duplicates ([subset,Â keep,Â inplace,Â ...]) Return DataFrame with duplicate rows removed. droplevel (level[,Â axis]) Return Series/DataFrame with requested index / column level(s) removed. dropna (*[,Â axis,Â how,Â thresh,Â subset,Â ...]) Remove missing values. duplicated ([subset,Â keep]) Return boolean Series denoting duplicate rows. eq (other[,Â axis,Â level]) Get Equal to of dataframe and other, element-wise (binary operator eq ). equals (other) Test whether two objects contain the same elements. eval (expr,Â *[,Â inplace]) Evaluate a string describing operations on DataFrame columns. ewm ([com,Â span,Â halflife,Â alpha,Â ...]) Provide exponentially weighted (EW) calculations. expanding ([min_periods,Â axis,Â method]) Provide expanding window calculations. explode (column[,Â ignore_index]) Transform each element of a list-like to a row, replicating index values. ffill (*[,Â axis,Â inplace,Â limit,Â limit_area,Â ...]) Fill NA/NaN values by propagating the last valid observation to next valid. fillna ([value,Â method,Â axis,Â inplace,Â ...]) Fill NA/NaN values using the specified method. filter ([items,Â like,Â regex,Â axis]) Subset the dataframe rows or columns according to the specified index labels. first (offset) (DEPRECATED) Select initial periods of time series data based on a date offset. first_valid_index () Return index for first non-NA value or None, if no non-NA value is found. floordiv (other[,Â axis,Â level,Â fill_value]) Get Integer division of dataframe and other, element-wise (binary operator floordiv ). from_dict (data[,Â orient,Â dtype,Â columns]) Construct DataFrame from dict of array-like or dicts. from_records (data[,Â index,Â exclude,Â ...]) Convert structured or record ndarray to DataFrame. ge (other[,Â axis,Â level]) Get Greater than or equal to of dataframe and other, element-wise (binary operator ge ). get (key[,Â default]) Get item from object for given key (ex: DataFrame column). groupby ([by,Â axis,Â level,Â as_index,Â sort,Â ...]) Group DataFrame using a mapper or by a Series of columns. gt (other[,Â axis,Â level]) Get Greater than of dataframe and other, element-wise (binary operator gt ). head ([n]) Return the first n rows. hist ([column,Â by,Â grid,Â xlabelsize,Â xrot,Â ...]) Make a histogram of the DataFrame's columns. idxmax ([axis,Â skipna,Â numeric_only]) Return index of first occurrence of maximum over requested axis. idxmin ([axis,Â skipna,Â numeric_only]) Return index of first occurrence of minimum over requested axis. infer_objects ([copy]) Attempt to infer better dtypes for object columns. info ([verbose,Â buf,Â max_cols,Â memory_usage,Â ...]) Print a concise summary of a DataFrame. insert (loc,Â column,Â value[,Â allow_duplicates]) Insert column into DataFrame at specified location. interpolate ([method,Â axis,Â limit,Â inplace,Â ...]) Fill NaN values using an interpolation method. isetitem (loc,Â value) Set the given value in the column with position loc . isin (values) Whether each element in the DataFrame is contained in values. isna () Detect missing values. isnull () DataFrame.isnull is an alias for DataFrame.isna. items () Iterate over (column name, Series) pairs. iterrows () Iterate over DataFrame rows as (index, Series) pairs. itertuples ([index,Â name]) Iterate over DataFrame rows as namedtuples. join (other[,Â on,Â how,Â lsuffix,Â rsuffix,Â ...]) Join columns of another DataFrame. keys () Get the 'info axis' (see Indexing for more). kurt ([axis,Â skipna,Â numeric_only]) Return unbiased kurtosis over requested axis. kurtosis ([axis,Â skipna,Â numeric_only]) Return unbiased kurtosis over requested axis. last (offset) (DEPRECATED) Select final periods of time series data based on a date offset. last_valid_index () Return index for last non-NA value or None, if no non-NA value is found. le (other[,Â axis,Â level]) Get Less than or equal to of dataframe and other, element-wise (binary operator le ). lt (other[,Â axis,Â level]) Get Less than of dataframe and other, element-wise (binary operator lt ). map (func[,Â na_action]) Apply a function to a Dataframe elementwise. mask (cond[,Â other,Â inplace,Â axis,Â level]) Replace values where the condition is True. max ([axis,Â skipna,Â numeric_only]) Return the maximum of the values over the requested axis. mean ([axis,Â skipna,Â numeric_only]) Return the mean of the values over the requested axis. median ([axis,Â skipna,Â numeric_only]) Return the median of the values over the requested axis. melt ([id_vars,Â value_vars,Â var_name,Â ...]) Unpivot a DataFrame from wide to long format, optionally leaving identifiers set. memory_usage ([index,Â deep]) Return the memory usage of each column in bytes. merge (right[,Â how,Â on,Â left_on,Â right_on,Â ...]) Merge DataFrame or named Series objects with a database-style join. min ([axis,Â skipna,Â numeric_only]) Return the minimum of the values over the requested axis. mod (other[,Â axis,Â level,Â fill_value]) Get Modulo of dataframe and other, element-wise (binary operator mod ). mode ([axis,Â numeric_only,Â dropna]) Get the mode(s) of each element along the selected axis. mul (other[,Â axis,Â level,Â fill_value]) Get Multiplication of dataframe and other, element-wise (binary operator mul ). multiply (other[,Â axis,Â level,Â fill_value]) Get Multiplication of dataframe and other, element-wise (binary operator mul ). ne (other[,Â axis,Â level]) Get Not equal to of dataframe and other, element-wise (binary operator ne ). nlargest (n,Â columns[,Â keep]) Return the first n rows ordered by columns in descending order. notna () Detect existing (non-missing) values. notnull () DataFrame.notnull is an alias for DataFrame.notna. nsmallest (n,Â columns[,Â keep]) Return the first n rows ordered by columns in ascending order. nunique ([axis,Â dropna]) Count number of distinct elements in specified axis. pad (*[,Â axis,Â inplace,Â limit,Â downcast]) (DEPRECATED) Fill NA/NaN values by propagating the last valid observation to next valid. pct_change ([periods,Â fill_method,Â limit,Â freq]) Fractional change between the current and a prior element. pipe (func,Â *args,Â **kwargs) Apply chainable functions that expect Series or DataFrames. pivot (*,Â columns[,Â index,Â values]) Return reshaped DataFrame organized by given index / column values. pivot_table ([values,Â index,Â columns,Â ...]) Create a spreadsheet-style pivot table as a DataFrame. pop (item) Return item and drop from frame. pow (other[,Â axis,Â level,Â fill_value]) Get Exponential power of dataframe and other, element-wise (binary operator pow ). prod ([axis,Â skipna,Â numeric_only,Â min_count]) Return the product of the values over the requested axis. product ([axis,Â skipna,Â numeric_only,Â min_count]) Return the product of the values over the requested axis. quantile ([q,Â axis,Â numeric_only,Â ...]) Return values at the given quantile over requested axis. query (expr,Â *[,Â inplace]) Query the columns of a DataFrame with a boolean expression. radd (other[,Â axis,Â level,Â fill_value]) Get Addition of dataframe and other, element-wise (binary operator radd ). rank ([axis,Â method,Â numeric_only,Â ...]) Compute numerical data ranks (1 through n) along axis. rdiv (other[,Â axis,Â level,Â fill_value]) Get Floating division of dataframe and other, element-wise (binary operator rtruediv ). reindex ([labels,Â index,Â columns,Â axis,Â ...]) Conform DataFrame to new index with optional filling logic. reindex_like (other[,Â method,Â copy,Â limit,Â ...]) Return an object with matching indices as other object. rename ([mapper,Â index,Â columns,Â axis,Â copy,Â ...]) Rename columns or index labels. rename_axis ([mapper,Â index,Â columns,Â axis,Â ...]) Set the name of the axis for the index or columns. reorder_levels (order[,Â axis]) Rearrange index levels using input order. replace ([to_replace,Â value,Â inplace,Â limit,Â ...]) Replace values given in to_replace with value . resample (rule[,Â axis,Â closed,Â label,Â ...]) Resample time-series data. reset_index ([level,Â drop,Â inplace,Â ...]) Reset the index, or a level of it. rfloordiv (other[,Â axis,Â level,Â fill_value]) Get Integer division of dataframe and other, element-wise (binary operator rfloordiv ). rmod (other[,Â axis,Â level,Â fill_value]) Get Modulo of dataframe and other, element-wise (binary operator rmod ). rmul (other[,Â axis,Â level,Â fill_value]) Get Multiplication of dataframe and other, element-wise (binary operator rmul ). rolling (window[,Â min_periods,Â center,Â ...]) Provide rolling window calculations. round ([decimals]) Round a DataFrame to a variable number of decimal places. rpow (other[,Â axis,Â level,Â fill_value]) Get Exponential power of dataframe and other, element-wise (binary operator rpow ). rsub (other[,Â axis,Â level,Â fill_value]) Get Subtraction of dataframe and other, element-wise (binary operator rsub ). rtruediv (other[,Â axis,Â level,Â fill_value]) Get Floating division of dataframe and other, element-wise (binary operator rtruediv ). sample ([n,Â frac,Â replace,Â weights,Â ...]) Return a random sample of items from an axis of object. select_dtypes ([include,Â exclude]) Return a subset of the DataFrame's columns based on the column dtypes. sem ([axis,Â skipna,Â ddof,Â numeric_only]) Return unbiased standard error of the mean over requested axis. set_axis (labels,Â *[,Â axis,Â copy]) Assign desired index to given axis. set_flags (*[,Â copy,Â allows_duplicate_labels]) Return a new object with updated flags. set_index (keys,Â *[,Â drop,Â append,Â inplace,Â ...]) Set the DataFrame index using existing columns. shift ([periods,Â freq,Â axis,Â fill_value,Â suffix]) Shift index by desired number of periods with an optional time freq . skew ([axis,Â skipna,Â numeric_only]) Return unbiased skew over requested axis. sort_index (*[,Â axis,Â level,Â ascending,Â ...]) Sort object by labels (along an axis). sort_values (by,Â *[,Â axis,Â ascending,Â ...]) Sort by the values along either axis. squeeze ([axis]) Squeeze 1 dimensional axis objects into scalars. stack ([level,Â dropna,Â sort,Â future_stack]) Stack the prescribed level(s) from columns to index. std ([axis,Â skipna,Â ddof,Â numeric_only]) Return sample standard deviation over requested axis. sub (other[,Â axis,Â level,Â fill_value]) Get Subtraction of dataframe and other, element-wise (binary operator sub ). subtract (other[,Â axis,Â level,Â fill_value]) Get Subtraction of dataframe and other, element-wise (binary operator sub ). sum ([axis,Â skipna,Â numeric_only,Â min_count]) Return the sum of the values over the requested axis. swapaxes (axis1,Â axis2[,Â copy]) (DEPRECATED) Interchange axes and swap values axes appropriately. swaplevel ([i,Â j,Â axis]) Swap levels i and j in a MultiIndex . tail ([n]) Return the last n rows. take (indices[,Â axis]) Return the elements in the given positional indices along an axis. to_clipboard (*[,Â excel,Â sep]) Copy object to the system clipboard. to_csv ([path_or_buf,Â sep,Â na_rep,Â ...]) Write object to a comma-separated values (csv) file. to_dict ([orient,Â into,Â index]) Convert the DataFrame to a dictionary. to_excel (excel_writer,Â *[,Â sheet_name,Â ...]) Write object to an Excel sheet. to_feather (path,Â **kwargs) Write a DataFrame to the binary Feather format. to_gbq (destination_table,Â *[,Â project_id,Â ...]) (DEPRECATED) Write a DataFrame to a Google BigQuery table. to_hdf (path_or_buf,Â *,Â key[,Â mode,Â ...]) Write the contained data to an HDF5 file using HDFStore. to_html ([buf,Â columns,Â col_space,Â header,Â ...]) Render a DataFrame as an HTML table. to_json ([path_or_buf,Â orient,Â date_format,Â ...]) Convert the object to a JSON string. to_latex ([buf,Â columns,Â header,Â index,Â ...]) Render object to a LaTeX tabular, longtable, or nested table. to_markdown ([buf,Â mode,Â index,Â storage_options]) Print DataFrame in Markdown-friendly format. to_numpy ([dtype,Â copy,Â na_value]) Convert the DataFrame to a NumPy array. to_orc ([path,Â engine,Â index,Â engine_kwargs]) Write a DataFrame to the ORC format. to_parquet ([path,Â engine,Â compression,Â ...]) Write a DataFrame to the binary parquet format. to_period ([freq,Â axis,Â copy]) Convert DataFrame from DatetimeIndex to PeriodIndex. to_pickle (path,Â *[,Â compression,Â protocol,Â ...]) Pickle (serialize) object to file. to_records ([index,Â column_dtypes,Â index_dtypes]) Convert DataFrame to a NumPy record array. to_sql (name,Â con,Â *[,Â schema,Â if_exists,Â ...]) Write records stored in a DataFrame to a SQL database. to_stata (path,Â *[,Â convert_dates,Â ...]) Export DataFrame object to Stata dta format. to_string ([buf,Â columns,Â col_space,Â header,Â ...]) Render a DataFrame to a console-friendly tabular output. to_timestamp ([freq,Â how,Â axis,Â copy]) Cast to DatetimeIndex of timestamps, at beginning of period. to_xarray () Return an xarray object from the pandas object. to_xml ([path_or_buffer,Â index,Â root_name,Â ...]) Render a DataFrame to an XML document. transform (func[,Â axis]) Call func on self producing a DataFrame with the same axis shape as self. transpose (*args[,Â copy]) Transpose index and columns. truediv (other[,Â axis,Â level,Â fill_value]) Get Floating division of dataframe and other, element-wise (binary operator truediv ). truncate ([before,Â after,Â axis,Â copy]) Truncate a Series or DataFrame before and after some index value. tz_convert (tz[,Â axis,Â level,Â copy]) Convert tz-aware axis to target time zone. tz_localize (tz[,Â axis,Â level,Â copy,Â ...]) Localize tz-naive index of a Series or DataFrame to target time zone. unstack ([level,Â fill_value,Â sort]) Pivot a level of the (necessarily hierarchical) index labels. update (other[,Â join,Â overwrite,Â ...]) Modify in place using non-NA values from another DataFrame. value_counts ([subset,Â normalize,Â sort,Â ...]) Return a Series containing the frequency of each distinct row in the Dataframe. var ([axis,Â skipna,Â ddof,Â numeric_only]) Return unbiased variance over requested axis. where (cond[,Â other,Â inplace,Â axis,Â level]) Replace values where the condition is False. xs (key[,Â axis,Â level,Â drop_level]) Return cross-section from the Series/DataFrame.


Page: https://github.com/pandas-dev/pandas/issues/new/choose



Page: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.__dataframe__.html#pandas.DataFrame.__dataframe__
pandas.DataFrame.__dataframe__ # DataFrame. __dataframe__ ( nan_as_null = False , allow_copy = True ) [source] # Return the dataframe interchange object implementing the interchange protocol. Parameters : nan_as_null bool, default False nan_as_null is DEPRECATED and has no effect. Please avoid using
it; it will be removed in a future release. allow_copy bool, default True Whether to allow memory copying when exporting. If set to False
it would cause non-zero-copy exports to fail. Returns : DataFrame interchange object The object which consuming library can use to ingress the dataframe. Notes Details on the interchange protocol: https://data-apis.org/dataframe-protocol/latest/index.html Examples >>> df_not_necessarily_pandas = pd . DataFrame ({ 'A' : [ 1 , 2 ], 'B' : [ 3 , 4 ]}) >>> interchange_object = df_not_necessarily_pandas . __dataframe__ () >>> interchange_object . column_names () Index(['A', 'B'], dtype='object') >>> df_pandas = ( pd . api . interchange . from_dataframe ... ( interchange_object . select_columns_by_name ([ 'A' ]))) >>> df_pandas A 0    1 1    2 These methods ( column_names , select_columns_by_name ) should work
for any dataframe library which implements the interchange protocol.


Page: https://github.com/pandas-dev/pandas/issues/56702



Page: https://github.com/pandas-dev/pandas/issues/57664



Page: https://github.com/pandas-dev/pandas/issues/57553



Page: https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html#pandas.to_datetime
pandas.to_datetime # pandas. to_datetime ( arg , errors='raise' , dayfirst=False , yearfirst=False , utc=False , format=None , exact=<no_default> , unit=None , infer_datetime_format=<no_default> , origin='unix' , cache=True ) [source] # Convert argument to datetime. This function converts a scalar, array-like, Series or DataFrame /dict-like to a pandas datetime object. Parameters : arg int, float, str, datetime, list, tuple, 1-d array, Series, DataFrame/dict-like The object to convert to a datetime. If a DataFrame is provided, the
method expects minimally the following columns: "year" , "month" , "day" . The column âyearâ
must be specified in 4-digit format. errors {âignoreâ, âraiseâ, âcoerceâ}, default âraiseâ If 'raise' , then invalid parsing will raise an exception. If 'coerce' , then invalid parsing will be set as NaT . If 'ignore' , then invalid parsing will return the input. dayfirst bool, default False Specify a date parse order if arg is str or is list-like.
If True , parses dates with the day first, e.g. "10/11/12" is parsed as 2012-11-10 . Warning dayfirst=True is not strict, but will prefer to parse
with day first. yearfirst bool, default False Specify a date parse order if arg is str or is list-like. If True parses dates with the year first, e.g. "10/11/12" is parsed as 2010-11-12 . If both dayfirst and yearfirst are True , yearfirst is
preceded (same as dateutil ). Warning yearfirst=True is not strict, but will prefer to parse
with year first. utc bool, default False Control timezone-related parsing, localization and conversion. If True , the function always returns a timezone-aware
UTC-localized Timestamp , Series or DatetimeIndex . To do this, timezone-naive inputs are localized as UTC, while timezone-aware inputs are converted to UTC. If False (default), inputs will not be coerced to UTC.
Timezone-naive inputs will remain naive, while timezone-aware ones
will keep their time offsets. Limitations exist for mixed
offsets (typically, daylight savings), see Examples section for details. Warning In a future version of pandas, parsing datetimes with mixed time
zones will raise an error unless utc=True .
Please specify utc=True to opt in to the new behaviour
and silence this warning. To create a Series with mixed offsets and object dtype, please use apply and datetime.datetime.strptime . See also: pandas general documentation about timezone conversion and
localization . format str, default None The strftime to parse time, e.g. "%d/%m/%Y" . See strftime documentation for more information on choices, though
note that "%f" will parse all the way up to nanoseconds.
You can also pass: âISO8601â, to parse any ISO8601 time string (not necessarily in exactly the same format); âmixedâ, to infer the format for each element individually. This is risky,
and you should probably use it along with dayfirst . Note If a DataFrame is passed, then format has no effect. exact bool, default True Control how format is used: If True , require an exact format match. If False , allow the format to match anywhere in the target
string. Cannot be used alongside format='ISO8601' or format='mixed' . unit str, default ânsâ The unit of the arg (D,s,ms,us,ns) denote the unit, which is an
integer or float number. This will be based off the origin.
Example, with unit='ms' and origin='unix' , this would calculate
the number of milliseconds to the unix epoch start. infer_datetime_format bool, default False If True and no format is given, attempt to infer the format
of the datetime strings based on the first non-NaN element,
and if it can be inferred, switch to a faster method of parsing them.
In some cases this can increase the parsing speed by ~5-10x. Deprecated since version 2.0.0: A strict version of this argument is now the default, passing it has
no effect. origin scalar, default âunixâ Define the reference date. The numeric values would be parsed as number
of units (defined by unit ) since this reference date. If 'unix' (or POSIX) time; origin is set to 1970-01-01. If 'julian' , unit must be 'D' , and origin is set to
beginning of Julian Calendar. Julian day number 0 is assigned
to the day starting at noon on January 1, 4713 BC. If Timestamp convertible (Timestamp, dt.datetime, np.datetimt64 or date
string), origin is set to Timestamp identified by origin. If a float or integer, origin is the difference
(in units determined by the unit argument) relative to 1970-01-01. cache bool, default True If True , use a cache of unique, converted dates to apply the
datetime conversion. May produce significant speed-up when parsing
duplicate date strings, especially ones with timezone offsets. The cache
is only used when there are at least 50 values. The presence of
out-of-bounds values will render the cache unusable and may slow down
parsing. Returns : datetime If parsing succeeded.
Return type depends on input (types in parenthesis correspond to
fallback in case of unsuccessful timezone or out-of-range timestamp
parsing): scalar: Timestamp (or datetime.datetime ) array-like: DatetimeIndex (or Series with object dtype containing datetime.datetime ) Series: Series of datetime64 dtype (or Series of object dtype containing datetime.datetime ) DataFrame: Series of datetime64 dtype (or Series of object dtype containing datetime.datetime ) Raises : ParserError When parsing a date from string fails. ValueError When another datetime conversion error happens. For example when one
of âyearâ, âmonthâ, dayâ columns is missing in a DataFrame , or
when a Timezone-aware datetime.datetime is found in an array-like
of mixed time offsets, and utc=False . See also DataFrame.astype Cast argument to a specified dtype. to_timedelta Convert argument to timedelta. convert_dtypes Convert dtypes. Notes Many input types are supported, and lead to different output types: scalars can be int, float, str, datetime object (from stdlib datetime module or numpy ). They are converted to Timestamp when
possible, otherwise they are converted to datetime.datetime .
None/NaN/null scalars are converted to NaT . array-like can contain int, float, str, datetime objects. They are
converted to DatetimeIndex when possible, otherwise they are
converted to Index with object dtype, containing datetime.datetime . None/NaN/null entries are converted to NaT in both cases. Series are converted to Series with datetime64 dtype when possible, otherwise they are converted to Series with object dtype, containing datetime.datetime . None/NaN/null
entries are converted to NaT in both cases. DataFrame/dict-like are converted to Series with datetime64 dtype. For each row a datetime is created from assembling
the various dataframe columns. Column keys can be common abbreviations
like [âyearâ, âmonthâ, âdayâ, âminuteâ, âsecondâ, âmsâ, âusâ, ânsâ]) or
plurals of the same. The following causes are responsible for datetime.datetime objects
being returned (possibly inside an Index or a Series with object dtype) instead of a proper pandas designated type
( Timestamp , DatetimeIndex or Series with datetime64 dtype): when any input element is before Timestamp.min or after Timestamp.max , see timestamp limitations . when utc=False (default) and the input is an array-like or Series containing mixed naive/aware datetime, or aware with mixed
time offsets. Note that this happens in the (quite frequent) situation when
the timezone has a daylight savings policy. In that case you may wish to
use utc=True . Examples Handling various input formats Assembling a datetime from multiple columns of a DataFrame . The keys
can be common abbreviations like [âyearâ, âmonthâ, âdayâ, âminuteâ, âsecondâ,
âmsâ, âusâ, ânsâ]) or plurals of the same >>> df = pd . DataFrame ({ 'year' : [ 2015 , 2016 ], ... 'month' : [ 2 , 3 ], ... 'day' : [ 4 , 5 ]}) >>> pd . to_datetime ( df ) 0   2015-02-04 1   2016-03-05 dtype: datetime64[ns] Using a unix epoch time >>> pd . to_datetime ( 1490195805 , unit = 's' ) Timestamp('2017-03-22 15:16:45') >>> pd . to_datetime ( 1490195805433502912 , unit = 'ns' ) Timestamp('2017-03-22 15:16:45.433502912') Warning For float arg, precision rounding might happen. To prevent
unexpected behavior use a fixed-width exact type. Using a non-unix epoch origin >>> pd . to_datetime ([ 1 , 2 , 3 ], unit = 'D' , ... origin = pd . Timestamp ( '1960-01-01' )) DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'], dtype='datetime64[ns]', freq=None) Differences with strptime behavior "%f" will parse all the way up to nanoseconds. >>> pd . to_datetime ( '2018-10-26 12:00:00.0000000011' , ... format = '%Y-%m- %d %H:%M:%S. %f ' ) Timestamp('2018-10-26 12:00:00.000000001') Non-convertible date/times Passing errors='coerce' will force an out-of-bounds date to NaT ,
in addition to forcing non-dates (or non-parseable dates) to NaT . >>> pd . to_datetime ( '13000101' , format = '%Y%m %d ' , errors = 'coerce' ) NaT Timezones and time offsets The default behaviour ( utc=False ) is as follows: Timezone-naive inputs are converted to timezone-naive DatetimeIndex : >>> pd . to_datetime ([ '2018-10-26 12:00:00' , '2018-10-26 13:00:15' ]) DatetimeIndex(['2018-10-26 12:00:00', '2018-10-26 13:00:15'], dtype='datetime64[ns]', freq=None) Timezone-aware inputs with constant time offset are converted to
timezone-aware DatetimeIndex : >>> pd . to_datetime ([ '2018-10-26 12:00 -0500' , '2018-10-26 13:00 -0500' ]) DatetimeIndex(['2018-10-26 12:00:00-05:00', '2018-10-26 13:00:00-05:00'], dtype='datetime64[ns, UTC-05:00]', freq=None) However, timezone-aware inputs with mixed time offsets (for example
issued from a timezone with daylight savings, such as Europe/Paris)
are not successfully converted to a DatetimeIndex .
Parsing datetimes with mixed time zones will show a warning unless utc=True . If you specify utc=False the warning below will be shown
and a simple Index containing datetime.datetime objects will be returned: >>> pd . to_datetime ([ '2020-10-25 02:00 +0200' , ... '2020-10-25 04:00 +0100' ]) FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`. Index([2020-10-25 02:00:00+02:00, 2020-10-25 04:00:00+01:00], dtype='object') A mix of timezone-aware and timezone-naive inputs is also converted to
a simple Index containing datetime.datetime objects: >>> from datetime import datetime >>> pd . to_datetime ([ "2020-01-01 01:00:00-01:00" , ... datetime ( 2020 , 1 , 1 , 3 , 0 )]) FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`. Index([2020-01-01 01:00:00-01:00, 2020-01-01 03:00:00], dtype='object') Setting utc=True solves most of the above issues: Timezone-naive inputs are localized as UTC >>> pd . to_datetime ([ '2018-10-26 12:00' , '2018-10-26 13:00' ], utc = True ) DatetimeIndex(['2018-10-26 12:00:00+00:00', '2018-10-26 13:00:00+00:00'], dtype='datetime64[ns, UTC]', freq=None) Timezone-aware inputs are converted to UTC (the output represents the
exact same datetime, but viewed from the UTC time offset +00:00 ). >>> pd . to_datetime ([ '2018-10-26 12:00 -0530' , '2018-10-26 12:00 -0500' ], ... utc = True ) DatetimeIndex(['2018-10-26 17:30:00+00:00', '2018-10-26 17:00:00+00:00'], dtype='datetime64[ns, UTC]', freq=None) Inputs can contain both string or datetime, the above
rules still apply >>> pd . to_datetime ([ '2018-10-26 12:00' , datetime ( 2020 , 1 , 1 , 18 )], utc = True ) DatetimeIndex(['2018-10-26 12:00:00+00:00', '2020-01-01 18:00:00+00:00'], dtype='datetime64[ns, UTC]', freq=None)


Page: https://github.com/pandas-dev/pandas/issues/57051



Page: https://github.com/pandas-dev/pandas/issues/55332



Page: https://github.com/pandas-dev/pandas/issues/57762



Page: https://github.com/pandas-dev/pandas/issues/57761



Page: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html#pandas.DataFrame.to_sql
pandas.DataFrame.to_sql # DataFrame. to_sql ( name , con , * , schema = None , if_exists = 'fail' , index = True , index_label = None , chunksize = None , dtype = None , method = None ) [source] # Write records stored in a DataFrame to a SQL database. Databases supported by SQLAlchemy [1] are supported. Tables can be
newly created, appended to, or overwritten. Parameters : name str Name of SQL table. con sqlalchemy.engine.(Engine or Connection) or sqlite3.Connection Using SQLAlchemy makes it possible to use any DB supported by that
library. Legacy support is provided for sqlite3.Connection objects. The user
is responsible for engine disposal and connection closure for the SQLAlchemy
connectable. See here .
If passing a sqlalchemy.engine.Connection which is already in a transaction,
the transaction will not be committed.  If passing a sqlite3.Connection,
it will not be possible to roll back the record insertion. schema str, optional Specify the schema (if database flavor supports this). If None, use
default schema. if_exists {âfailâ, âreplaceâ, âappendâ}, default âfailâ How to behave if the table already exists. fail: Raise a ValueError. replace: Drop the table before inserting new values. append: Insert new values to the existing table. index bool, default True Write DataFrame index as a column. Uses index_label as the column
name in the table. Creates a table index for this column. index_label str or sequence, default None Column label for index column(s). If None is given (default) and index is True, then the index names are used.
A sequence should be given if the DataFrame uses MultiIndex. chunksize int, optional Specify the number of rows in each batch to be written at a time.
By default, all rows will be written at once. dtype dict or scalar, optional Specifying the datatype for columns. If a dictionary is used, the
keys should be the column names and the values should be the
SQLAlchemy types or strings for the sqlite3 legacy mode. If a
scalar is provided, it will be applied to all columns. method {None, âmultiâ, callable}, optional Controls the SQL insertion clause used: None : Uses standard SQL INSERT clause (one per row). âmultiâ: Pass multiple values in a single INSERT clause. callable with signature (pd_table, conn, keys, data_iter) . Details and a sample callable implementation can be found in the
section insert method . Returns : None or int Number of rows affected by to_sql. None is returned if the callable
passed into method does not return an integer number of rows. The number of returned rows affected is the sum of the rowcount attribute of sqlite3.Cursor or SQLAlchemy connectable which may not
reflect the exact number of written rows as stipulated in the sqlite3 or SQLAlchemy . Added in version 1.4.0. Raises : ValueError When the table already exists and if_exists is âfailâ (the
default). See also read_sql Read a DataFrame from a table. Notes Timezone aware datetime columns will be written as Timestamp with timezone type with SQLAlchemy if supported by the
database. Otherwise, the datetimes will be stored as timezone unaware
timestamps local to the original timezone. Not all datastores support method="multi" . Oracle, for example,
does not support multi-value insert. References [ 1 ] https://docs.sqlalchemy.org [ 2 ] https://www.python.org/dev/peps/pep-0249/ Examples Create an in-memory SQLite database. >>> from sqlalchemy import create_engine >>> engine = create_engine ( 'sqlite://' , echo = False ) Create a table from scratch with 3 rows. >>> df = pd . DataFrame ({ 'name' : [ 'User 1' , 'User 2' , 'User 3' ]}) >>> df name 0  User 1 1  User 2 2  User 3 >>> df . to_sql ( name = 'users' , con = engine ) 3 >>> from sqlalchemy import text >>> with engine . connect () as conn : ... conn . execute ( text ( "SELECT * FROM users" )) . fetchall () [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')] An sqlalchemy.engine.Connection can also be passed to con : >>> with engine . begin () as connection : ... df1 = pd . DataFrame ({ 'name' : [ 'User 4' , 'User 5' ]}) ... df1 . to_sql ( name = 'users' , con = connection , if_exists = 'append' ) 2 This is allowed to support operations that require that the same
DBAPI connection is used for the entire operation. >>> df2 = pd . DataFrame ({ 'name' : [ 'User 6' , 'User 7' ]}) >>> df2 . to_sql ( name = 'users' , con = engine , if_exists = 'append' ) 2 >>> with engine . connect () as conn : ... conn . execute ( text ( "SELECT * FROM users" )) . fetchall () [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'), (0, 'User 4'), (1, 'User 5'), (0, 'User 6'), (1, 'User 7')] Overwrite the table with just df2 . >>> df2 . to_sql ( name = 'users' , con = engine , if_exists = 'replace' , ... index_label = 'id' ) 2 >>> with engine . connect () as conn : ... conn . execute ( text ( "SELECT * FROM users" )) . fetchall () [(0, 'User 6'), (1, 'User 7')] Use method to define a callable insertion method to do nothing
if thereâs a primary key conflict on a table in a PostgreSQL database. >>> from sqlalchemy.dialects.postgresql import insert >>> def insert_on_conflict_nothing ( table , conn , keys , data_iter ): ... # "a" is the primary key in "conflict_table" ... data = [ dict ( zip ( keys , row )) for row in data_iter ] ... stmt = insert ( table . table ) . values ( data ) . on_conflict_do_nothing ( index_elements = [ "a" ]) ... result = conn . execute ( stmt ) ... return result . rowcount >>> df_conflict . to_sql ( name = "conflict_table" , con = conn , if_exists = "append" , method = insert_on_conflict_nothing ) 0 For MySQL, a callable to update columns b and c if thereâs a conflict
on a primary key. >>> from sqlalchemy.dialects.mysql import insert >>> def insert_on_conflict_update ( table , conn , keys , data_iter ): ... # update columns "b" and "c" on primary key conflict ... data = [ dict ( zip ( keys , row )) for row in data_iter ] ... stmt = ( ... insert ( table . table ) ... . values ( data ) ... ) ... stmt = stmt . on_duplicate_key_update ( b = stmt . inserted . b , c = stmt . inserted . c ) ... result = conn . execute ( stmt ) ... return result . rowcount >>> df_conflict . to_sql ( name = "conflict_table" , con = conn , if_exists = "append" , method = insert_on_conflict_update ) 2 Specify the dtype (especially useful for integers with missing values).
Notice that while pandas is forced to store the data as floating point,
the database supports nullable integers. When fetching the data with
Python, we get back integer scalars. >>> df = pd . DataFrame ({ "A" : [ 1 , None , 2 ]}) >>> df A 0  1.0 1  NaN 2  2.0 >>> from sqlalchemy.types import Integer >>> df . to_sql ( name = 'integers' , con = engine , index = False , ... dtype = { "A" : Integer ()}) 3 >>> with engine . connect () as conn : ... conn . execute ( text ( "SELECT * FROM integers" )) . fetchall () [(1,), (None,), (2,)]


Page: https://github.com/pandas-dev/pandas/issues/57539

